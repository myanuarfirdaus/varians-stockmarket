{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.alphavantage import AlphaVantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame as df, Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'6PE06AMZAM1MCGFX'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "_API_KEY_TEST1 = \"G23MAAVKWB5TMPMV\"\n",
    "_API_KEY_TEST2 = \"6PE06AMZAM1MCGFX\" #myanuarfirdaus\n",
    "_API_KEY_TEST3 = \"6HZYCBP71FGOR1O5\" #myanuarfirdaus23\n",
    "_API_KEY_TEST4 = \"X5LNMI2AESR1YQCU\" #muh_yanuar_firdaus@yahoo.com\n",
    "\n",
    "names=[_API_KEY_TEST1,_API_KEY_TEST2,_API_KEY_TEST3,_API_KEY_TEST4]\n",
    "\n",
    "selected_names=set()\n",
    "while len(selected_names)<1:\n",
    "   random.shuffle(names)\n",
    "   indx=random.randint(0,len(names)-1)\n",
    "   selected_names = names[indx]\n",
    "\n",
    "_API_KEY_TEST = repr(selected_names)\n",
    "print (_API_KEY_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory /Varians failed\n"
     ]
    }
   ],
   "source": [
    "#creating folder on C:\n",
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = \"/Varians\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type your entity: ATAC\n"
     ]
    }
   ],
   "source": [
    "entity= input('Please type your entity: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call data API Fundamental Quarterly\n",
    "fd = FundamentalData(key=_API_KEY_TEST, output_format='pandas')\n",
    "# Get json object with the intraday data and another with  the call's metadata\n",
    "\n",
    "data1, meta_data = fd.get_income_statement_quarterly(entity)  #get income statement quarterly data\n",
    "data2, meta_data = fd.get_cash_flow_quarterly(entity) #get cash flow quarterly data\n",
    "data3, meta_data = fd.get_balance_sheet_quarterly(entity) #get balance sheet quarterly data\n",
    "\n",
    "API_URL = \"https://www.alphavantage.co/query\"\n",
    "data = {\n",
    "     \"function\": \"OVERVIEW\",\n",
    "     \"symbol\": entity,\n",
    "     \"outputsize\": \"compact\",\n",
    "     \"datatype\": \"json\",\n",
    "     \"apikey\": _API_KEY_TEST,\n",
    "     }\n",
    "response = requests.get(API_URL, data)\n",
    "Company_Overview = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call data timeseries last price monthly\n",
    "ts = TimeSeries(key=_API_KEY_TEST, output_format='pandas')\n",
    "last_price, meta_data = ts.get_monthly(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write API to csv as buffer file\n",
    "data1.to_csv(r'C:\\Varians\\Income Statement Quarterly.csv', index=None, header=True)\n",
    "data2.to_csv(r'C:\\Varians\\Cash Flow Quarterly.csv', index=None, header=True)\n",
    "data3.to_csv(r'C:\\Varians\\Balance Sheet Quarterly.csv', index=None, header=True)\n",
    "last_price.to_csv(r'C:\\Varians\\Last Price.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "OV = {}\n",
    "OV = Company_Overview\n",
    "split_OV=OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write tuple/list overview to csv file\n",
    "with open(r'C:\\Varians\\Overview2.csv', 'w') as g:\n",
    "    writer1=csv.writer(g,lineterminator='\\n')\n",
    "    writer1.writerow(split_OV.keys())\n",
    "    writer1.writerow(split_OV.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file to pull data for calculation variable\n",
    "import pandas as pd\n",
    "with open(r'C:\\Varians\\Income Statement Quarterly.csv') as ISQ:\n",
    "    ISQ_reader = pd.read_csv(ISQ)\n",
    "    \n",
    "with open(r'C:\\Varians\\Cash Flow Quarterly.csv') as CFQ:\n",
    "    CFQ_reader = pd.read_csv(CFQ)\n",
    "    \n",
    "with open(r'C:\\Varians\\Balance Sheet Quarterly.csv') as BSQ:\n",
    "    BSQ_reader = pd.read_csv(BSQ)\n",
    "    \n",
    "with open(r'C:\\Varians\\Last Price.csv') as LP:\n",
    "    LP_reader = pd.read_csv(LP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date from object to datetime64\n",
    "ISQ_reader.fiscalDateEnding=ISQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "ISQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True) #to change string none to NaN\n",
    "ISQ_reader.fillna(value=0,inplace=True)\n",
    "CFQ_reader.fiscalDateEnding=CFQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "CFQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "CFQ_reader.fillna(value=0,inplace=True)\n",
    "BSQ_reader.fiscalDateEnding=BSQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "BSQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "BSQ_reader.fillna(value=0,inplace=True)\n",
    "BSQ_reader[\"commonStockSharesOutstanding\"] = BSQ_reader.commonStockSharesOutstanding.astype(float) #to change  data type of SO\n",
    "LP_reader.date=LP_reader.date.astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = BSQ_reader.columns.drop('fiscalDateEnding')\n",
    "BSQ_reader[cols] = BSQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "cols = ISQ_reader.columns.drop('fiscalDateEnding')\n",
    "ISQ_reader[cols] = ISQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "cols = CFQ_reader.columns.drop('fiscalDateEnding')\n",
    "CFQ_reader[cols] = CFQ_reader[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make fundamental data from quarterly to monthly and fill forward NaN data with previous quarterly data\n",
    "#this code only apply on int or float data types\n",
    "#resample made the date ascending, while data from time series is descending. Why not just LP became ascending? Because LP has longer date than the other data\n",
    "ISQ_monthly=ISQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "ISQ_monthly.fillna(method='ffill',inplace=True)\n",
    "ISQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "CFQ_monthly=CFQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "CFQ_monthly.fillna(method='ffill',inplace=True)\n",
    "CFQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "BSQ_monthly=BSQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "BSQ_monthly.fillna(method='ffill',inplace=True)\n",
    "BSQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for add rows to fundamental rows to be equal with timeseries rows and fill nan\n",
    "def addrow(source,target,ori_table):\n",
    "    data=[]\n",
    "    #y=pd.DataFrame()\n",
    "    counter=0\n",
    "    for i in range(0,10):\n",
    "        if source[i]==target[0]:\n",
    "            break\n",
    "        counter+=1\n",
    "    for j in range(0,counter):\n",
    "        data.insert(j, {np.NaN,np.NaN,np.NaN})\n",
    "    y=pd.concat([pd.DataFrame(data), ori_table], ignore_index=True) #repeat for all variable\n",
    "    y.fillna(method='bfill',inplace=True)\n",
    "    return [y,counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 3 is not in range",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-d33c9fdc31d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mTS_table\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mLP_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetIncome\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'4. close'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtempaddrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maddrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTS_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mISQ_monthly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfiscalDateEnding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdict_table\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#use addrow function to add row to equal TS table row with quarter table row\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mdatincome\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtempaddrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mcounter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtempaddrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-66d76de0e6fd>\u001b[0m in \u001b[0;36maddrow\u001b[1;34m(source, target, ori_table)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcounter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 882\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 989\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    990\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\range.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m    355\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_range\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    358\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 3"
     ]
    }
   ],
   "source": [
    "#call all data needed for calculation and clean it first and wrap it into single variable list\n",
    "ISQ_monthly.reset_index(inplace=True)\n",
    "SO = BSQ_monthly['commonStockSharesOutstanding']\n",
    "netIncome = ISQ_monthly['netIncome']\n",
    "TA = BSQ_monthly['totalAssets']\n",
    "TL = BSQ_monthly['totalLiabilities']\n",
    "TSE = BSQ_monthly['totalShareholderEquity']\n",
    "cash = BSQ_monthly['cash']\n",
    "STD = BSQ_monthly['shortTermDebt']\n",
    "LTD = BSQ_monthly['longTermDebt']\n",
    "EBIT = ISQ_monthly['ebit']\n",
    "DEPR = CFQ_monthly['depreciation']\n",
    "AMOR = BSQ_monthly['accumulatedAmortization']\n",
    "\n",
    "dict_table=pd.DataFrame(list(zip(SO,netIncome,TA,TL,TSE,cash,STD,LTD,EBIT,DEPR,AMOR)))\n",
    "TS_table=LP_reader.loc[0:(len(netIncome)), ['date', '4. close']]\n",
    "\n",
    "tempaddrow=addrow(TS_table.date,ISQ_monthly.fiscalDateEnding,dict_table) #use addrow function to add row to equal TS table row with quarter table row\n",
    "datincome=pd.DataFrame(tempaddrow[0])\n",
    "counter=tempaddrow[1]\n",
    "allsindex=datincome.set_axis(['SO','netIncome','TA','TL','TSE','cash','STD','LTD','EBIT','DEPR','AMOR'], axis='columns')\n",
    "TS_table=LP_reader.loc[0:(len(netIncome)+counter), ['date', '4. close']]\n",
    "TS_table=TS_table.rename(columns={\"4. close\": \"LastPrice\"})\n",
    "inputmerge=TS_table.merge(allsindex, left_index=True, right_index=True)\n",
    "print(inputmerge)\n",
    "#print(tempaddrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for making TTM data\n",
    "def makettm(tabtemp,x):\n",
    "    tabtemp = DataFrame(tabtemp)\n",
    "    width = x\n",
    "    shifted = tabtemp.shift(0)\n",
    "    window = shifted.rolling(window=width)\n",
    "    test = window.sum()\n",
    "    complete = test.fillna(value=0)\n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculating EPS TTM (Trailing Twelve Months) for PER input\n",
    "\n",
    "#calculation for EPS Quarterly\n",
    "from pandas import DataFrame\n",
    "Tableeps =pd.DataFrame()\n",
    "Tableeps ['Date'] = ISQ_reader.fiscalDateEnding\n",
    "Tableeps ['NIQ'] = ISQ_reader.netIncome\n",
    "Tableeps ['SOQ'] = BSQ_reader.commonStockSharesOutstanding\n",
    "Tableeps = Tableeps.sort_index(ascending=False)\n",
    "Tableeps = Tableeps.reset_index(drop=True)\n",
    "EPStemps = [Tableeps.NIQ[i]/Tableeps.SOQ[i] for i in range(len(Tableeps.SOQ))]\n",
    "NIQtemps = Tableeps.NIQ\n",
    "\n",
    "#Make EPSTTM table from function makettm \n",
    "EPSTTM = makettm(EPStemps,4)\n",
    "Tableeps ['EPSTTM'] = pd.DataFrame(EPSTTM)\n",
    "\n",
    "#make netIncome TTM table from function makettm\n",
    "NITTM = makettm(NIQtemps,4)\n",
    "Tableeps['NITTM']=pd.DataFrame(NITTM)\n",
    "\n",
    "Tableeps=Tableeps.resample('M', on='Date').mean()\n",
    "Tableeps.fillna(method='ffill',inplace=True)\n",
    "Tableeps = Tableeps.sort_index(ascending=False)\n",
    "Tableeps.reset_index(inplace=True)\n",
    "Coldate = Tableeps.Date\n",
    "Tableeps = Tableeps.set_index('Date')\n",
    "temp= addrow(TS_table.date,Coldate,Tableeps)\n",
    "TTMmonth = temp[0]\n",
    "print(TTMmonth)\n",
    "print(Tableeps)\n",
    "#gimana ngeluarin function result ke dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculation\n",
    "#columns=['EPS']\n",
    "from pandas import DataFrame\n",
    "Calculation = pd.DataFrame()\n",
    "\n",
    "inputcalc = inputmerge\n",
    "inputcalc = inputcalc.sort_index(ascending=False)\n",
    "inputcalc = inputcalc.reset_index(drop=True)\n",
    "\n",
    "#for i in range (len(SO)):\n",
    "Calculation ['Date'] = inputcalc.date\n",
    "Calculation ['LastPrice'] = inputcalc.LastPrice\n",
    "Calculation ['ShareOut'] = inputcalc.SO\n",
    "Calculation ['MarketCap'] = [inputcalc.LastPrice[i]*inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EPS'] = [inputcalc.netIncome[i]/inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "\n",
    "#Merging TTM EPS\n",
    "temp = pd.DataFrame()\n",
    "temp['EPSTTM'] = (TTMmonth.EPSTTM)\n",
    "temp['NITTM'] = TTMmonth.NITTM\n",
    "temp = temp.sort_index(ascending=False)\n",
    "temp.reset_index(inplace=True)\n",
    "#Calculation = Calculation.merge(EPSTTM, left_index=True, right_index=True)\n",
    "\n",
    "Calculation ['EPSTTM'] = temp.EPSTTM\n",
    "Calculation ['PER'] = [inputcalc.LastPrice[i]/temp.EPSTTM[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['BVPS'] = [(inputcalc.TA[i]-inputcalc.TL[i])/inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['PBV'] = [Calculation.LastPrice[i]/Calculation.BVPS[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['ROA%'] = [temp.NITTM[i]/inputcalc.TA[i]*100 for i in range(len(inputcalc.SO))]\n",
    "Calculation ['ROE%'] = [temp.NITTM[i]/inputcalc.TSE[i]*100 for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EV'] = [Calculation.MarketCap[i]+inputcalc.cash[i]-(inputcalc.STD[i]+inputcalc.LTD[i]) for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EBITDA'] = [inputcalc.EBIT[i]+inputcalc.DEPR[i]+inputcalc.AMOR[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EV/EBITDA'] = [Calculation.EV[i]/Calculation.EBITDA[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['D/E'] = [inputcalc.TL[i]/inputcalc.TSE[i] for i in range(len(inputcalc.TL))]\n",
    "Calculation ['Debt/Totalcap'] = [(inputcalc.STD[i]+inputcalc.LTD[i])/(inputcalc.STD[i]+inputcalc.LTD[i]+inputcalc.TSE[i]) for i in range(len(inputcalc.STD))]\n",
    "Calculation ['Debt/EBITDA'] = [(inputcalc.STD[i]+inputcalc.LTD[i])/Calculation.EBITDA[i] for i in range(len(inputcalc.STD)) ]\n",
    "\n",
    "Calculation = Calculation.replace([np.inf, -np.inf], 0)\n",
    "print(Calculation.tail(30))\n",
    "print(Calculation.dtypes)\n",
    "\n",
    "Calculation.to_csv(r'F:\\Kydi\\Varians\\Calculation.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(Calculation.columns)\n",
    "len(Calculation)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "len(Calculation[list(Calculation.columns)[0]])\n",
    "Calculation['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "mysql_list = []\n",
    "Unique_ID  = []\n",
    "StockName  = [entity.upper()]*len(Calculation['Date'])  \n",
    "\n",
    "for i in range (len(Calculation['Date'])) :\n",
    "    temp = entity +\"_\"+ str(Calculation['Date'][i].strftime('%Y_%m_%d'))\n",
    "    Unique_ID.append(temp)\n",
    "    i += 1\n",
    "\n",
    "mysql_list.append(Unique_ID)\n",
    "mysql_list.append(StockName)\n",
    "\n",
    "for i in list(Calculation.columns) :\n",
    "    mysql_list.append(Calculation[i])\n",
    "    \n",
    "print(mysql_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module for mysql \n",
    "import mplfinance as mpf\n",
    "from os import path\n",
    "import mysql.connector as mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(db_name):\n",
    "    try:\n",
    "        return mysql.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='Pertamina123',\n",
    "            database=db_name)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = connect(\"newstockmarket\")\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------\n",
    "    atable = \"stockdata_query\"\n",
    "    _SQL = \"\"\"SHOW TABLES\"\"\"\n",
    "    cursor.execute(_SQL)\n",
    "    results = cursor.fetchall()\n",
    "    \n",
    "    results_list = [item[0] for item in results] # Conversion to list of str\n",
    "    \n",
    "    create_table = (\"CREATE TABLE {table} \"\n",
    "                   \" ( UNIQUE_ID VARCHAR(50) NOT NULL PRIMARY KEY, STOCKNAME VARCHAR(50) NOT NULL, \"\n",
    "                   \" DATE date NOT NULL, LAST_PRICE_RP decimal(8, 2) NOT NULL,\"\n",
    "                   \" SHARE_OUT decimal(15, 2) NOT NULL, MARKET_CAP_RP decimal(15, 2) NOT NULL, \"\n",
    "                   \" DEVIDEN_RP decimal(15, 2) NOT NULL,  EPSTTMM_RP decimal(15, 2) NOT NULL, \"\n",
    "                   \" PER_X decimal(15, 2) NOT NULL, BVPS_RP decimal(15, 2) NOT NULL, \"\n",
    "                   \" PBV_X decimal(15, 2) NOT NULL, ROA_PERCENT decimal(15, 2) NOT NULL, \"\n",
    "                   \" ROE_PERCENT decimal(15, 2) NOT NULL, EV decimal(15, 2) NOT NULL, \"\n",
    "                   \" EBITDA decimal(15, 2) NOT NULL, EV_EBITDA_RATIO decimal(15, 2) NOT NULL, \"\n",
    "                   \" D_E_RATIO decimal(15, 2) NOT NULL, DEBT_TOTALCAP_RATIO decimal(15, 2) NOT NULL, \"\n",
    "                   \" DEBT_EBITDA_RATIO decimal(15, 2) NOT NULL ) \"\n",
    "                   )\n",
    "    \n",
    "    if atable in results_list:\n",
    "        print(atable, 'was found! not creating new table \\n')\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        cursor = db.cursor()\n",
    "        #cursor.execute(\"CREATE TABLE MSFT (  Date date NOT NULL PRIMARY KEY, Open decimal(8, 2) NOT NULL,  High decimal(8, 2) NOT NULL,  Low decimal(8, 2) NOT NULL , Close decimal(8, 2) NOT NULL)\" )\n",
    "        cursor.execute(create_table.format(table=atable) )\n",
    "#------------------------------------------------------------------------------------------\n",
    "    \n",
    "    j = 0\n",
    "    insert_table = (\"INSERT IGNORE INTO {table} \"\n",
    "                   \"(UNIQUE_ID, STOCKNAME, DATE, LAST_PRICE_RP, SHARE_OUT, MARKET_CAP_RP, \"\n",
    "                   \"DEVIDEN_RP, EPSTTMM_RP, PER_X, BVPS_RP, PBV_X, ROA_PERCENT, ROE_PERCENT, \"\n",
    "                   \"EV, EBITDA, EV_EBITDA_RATIO, D_E_RATIO, DEBT_TOTALCAP_RATIO, \"\n",
    "                   \"DEBT_EBITDA_RATIO) \"\n",
    "                   \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "    while j < len(mysql_list[0]) :\n",
    "        project_data = []\n",
    "        i = 0\n",
    "        while i < len(mysql_list) :\n",
    "            project_data.append(str (mysql_list[i][j]))\n",
    "            #print(project_data)\n",
    "            i += 1\n",
    "        \n",
    "        cursor.execute(insert_table.format(table=atable), project_data)\n",
    "        j += 1\n",
    "        \n",
    "    db.commit()\n",
    "\n",
    "    select_table = (\"SELECT * FROM {table} \")\n",
    "    cursor.execute(select_table.format(table=atable))\n",
    "    project_records = cursor.fetchall()\n",
    "    \n",
    "    #print(project_records)\n",
    "\n",
    "    db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split_OV)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
