{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory /Varians failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-f82d77aa57d9>:129: FutureWarning: set_axis currently defaults to operating inplace.\n",
      "This will change in a future version of pandas, use inplace=True to avoid this warning.\n",
      "  stocklist = stocklist.set_axis(['company','market','ticker'], axis='columns')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'ticker'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f82d77aa57d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[0mstocklist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstocklist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'company'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'market'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'ticker'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'columns'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mstocklist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstocklist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mticker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;31m# _API_KEY_TEST1 = 'G23MAAVKWB5TMPMV'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'ticker'"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.alphavantage import AlphaVantage\n",
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df, Timestamp\n",
    "import csv\n",
    "import ast\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "#import module for mysql \n",
    "import mplfinance as mpf\n",
    "from os import path\n",
    "import mysql.connector as mysql\n",
    "from pandas import DataFrame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def randomize () :\n",
    "    global zkey\n",
    "    global _API_KEY_TEST\n",
    "    zkey += 1\n",
    "    maxcounter = len(names) - 1\n",
    "    if zkey > maxcounter :\n",
    "        zkey = 0\n",
    "    _API_KEY_TEST = names[zkey]\n",
    "    print (\"the API key right now is : \"+_API_KEY_TEST)\n",
    "    return _API_KEY_TEST\n",
    "\n",
    "#function for making TTM data\n",
    "def makettm(tabtemp,x):\n",
    "    tabtemp = DataFrame(tabtemp)\n",
    "    width = x\n",
    "    shifted = tabtemp.shift(0)\n",
    "    window = shifted.rolling(window=width)\n",
    "    test = window.sum()\n",
    "    complete = test.fillna(value=0)\n",
    "    return complete\n",
    "\n",
    "#function for add rows to fundamental rows to be equal with timeseries rows and fill nan\n",
    "def addrow(source,target,ori_table):\n",
    "    data=[]\n",
    "    #y=pd.DataFrame()\n",
    "    counter=0\n",
    "    for i in range(0,10):\n",
    "        if source[i]==target[0]:\n",
    "            break\n",
    "        counter+=1\n",
    "    for j in range(0,counter):\n",
    "        data.insert(j, {np.NaN,np.NaN,np.NaN})\n",
    "    y=pd.concat([pd.DataFrame(data), ori_table], ignore_index=True) #repeat for all variable\n",
    "    y.fillna(method='bfill',inplace=True)\n",
    "    return [y,counter]\n",
    "\n",
    "def connect(db_name):\n",
    "    try:\n",
    "        return mysql.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='minyak23',\n",
    "            database=db_name)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "def step_1() :\n",
    "    global step \n",
    "    step = \"step_1\"\n",
    "    data1, meta_data = fd.get_income_statement_quarterly(entity)  #get income statement quarterly data\n",
    "    data1.to_csv(r'C:\\Varians\\Income Statement Quarterly.csv', index=None, header=True)\n",
    "    print(\"Succsesfully Pull Data 1 from web\")\n",
    "def step_2() :  \n",
    "    global step \n",
    "    step = \"step_2\"\n",
    "    data2, meta_data = fd.get_cash_flow_quarterly(entity) #get cash flow quarterly data\n",
    "    data2.to_csv(r'C:\\Varians\\Cash Flow Quarterly.csv', index=None, header=True)\n",
    "    print(\"Succsesfully Pull Data 2 from web\")\n",
    "def step_3():\n",
    "    global step \n",
    "    step = \"step_3\"\n",
    "    data3, meta_data = fd.get_balance_sheet_quarterly(entity) #get balance sheet quarterly data\n",
    "    data3.to_csv(r'C:\\Varians\\Balance Sheet Quarterly.csv', index=None, header=True)\n",
    "    print(\"Succsesfully Pull Data 3 from web\")\n",
    "def step_4():\n",
    "    global OV\n",
    "    OV = {}\n",
    "    global step \n",
    "    step = \"step_4\"\n",
    "    API_URL = \"https://www.alphavantage.co/query\"\n",
    "    data = {\n",
    "    \"function\": \"OVERVIEW\",\n",
    "    \"symbol\": entity,\n",
    "    \"outputsize\": \"compact\",\n",
    "    \"datatype\": \"json\",\n",
    "    \"apikey\": _API_KEY_TEST,\n",
    "    }\n",
    "    response = requests.get(API_URL, data)\n",
    "    OV = response.json()\n",
    "    split_OV=OV\n",
    "    #write tuple/list overview to csv file\n",
    "    with open(r'C:\\Varians\\Overview2.csv', 'w') as g:\n",
    "        writer1=csv.writer(g,lineterminator='\\n')\n",
    "        writer1.writerow(split_OV.keys())\n",
    "        writer1.writerow(split_OV.values())\n",
    "    print(\"Succsesfully Pull Data Overview from web\")\n",
    "        \n",
    "def step_5():\n",
    "    global step \n",
    "    step = \"step_5\"\n",
    "    ts = TimeSeries(key=_API_KEY_TEST, output_format='pandas')\n",
    "    last_price, meta_data = ts.get_monthly(entity)\n",
    "    last_price.to_csv(r'C:\\Varians\\Last Price.csv', index=True, header=True)\n",
    "    print(\"Succsesfully Pull Data Timeseries from web\")\n",
    "\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = \"/Varians\"\n",
    "#creating folder on C:\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % path)\n",
    "\n",
    "with open(r'C:\\Varians\\stocklist.csv') as slist:\n",
    "    stocklist = pd.read_csv(slist, header = None)\n",
    "    \n",
    "stocklist = stocklist.set_axis(['company','market','ticker'], axis='columns')\n",
    "stocklist.ticker = stocklist.ticker.str.strip()\n",
    "\n",
    "# _API_KEY_TEST1 = 'G23MAAVKWB5TMPMV'\n",
    "# _API_KEY_TEST2 = '6PE06AMZAM1MCGFX' #myanuarfirdaus\n",
    "# _API_KEY_TEST3 = '6HZYCBP71FGOR1O5' #myanuarfirdaus23\n",
    "_API_KEY_TEST4 = 'X5LNMI2AESR1YQCU' #muh_yanuar_firdaus@yahoo.com\n",
    "_API_KEY_TEST5 = 'YBBKWRK4VSTP4GZH' #anggiengineer@yahoo.com\n",
    "_API_KEY_TEST6 = 'X3Z3LQ31Z9B1OYX9' #myanuarfirdaus@hotmail.com\n",
    "# names = [_API_KEY_TEST1,_API_KEY_TEST2,_API_KEY_TEST3,_API_KEY_TEST4,_API_KEY_TEST5,_API_KEY_TEST6]\n",
    "names = [_API_KEY_TEST4,_API_KEY_TEST5,_API_KEY_TEST6]\n",
    "\n",
    "for zticker in list (stocklist.ticker) :\n",
    "    entity = str(zticker)\n",
    "    print (\"Stock Ticker Name : \"+entity)\n",
    "    _API_KEY_TEST = \"\"\n",
    "    zkey = 0\n",
    "    step = \"\"\n",
    "    df_OV = pd.DataFrame()\n",
    "    ISQ_reader = pd.DataFrame()\n",
    "    CFQ_reader = pd.DataFrame()\n",
    "    BSQ_reader = pd.DataFrame()\n",
    "    dict_table = pd.DataFrame()\n",
    "    \n",
    "    randomize()\n",
    "    \n",
    "    #call data API Fundamental Quarterly\n",
    "    fd = FundamentalData(key=_API_KEY_TEST, output_format='pandas')\n",
    "    procedure = [step_1,step_2,step_3,step_4,step_5]\n",
    "    \n",
    "    while True :\n",
    "        try : \n",
    "            for i in procedure :\n",
    "                i()\n",
    "\n",
    "            #read csv file to pull data for calculation variable\n",
    "            with open(r'C:\\Varians\\Income Statement Quarterly.csv') as ISQ:\n",
    "                ISQ_reader = pd.read_csv(ISQ)\n",
    "\n",
    "            with open(r'C:\\Varians\\Cash Flow Quarterly.csv') as CFQ:\n",
    "                CFQ_reader = pd.read_csv(CFQ)\n",
    "\n",
    "            with open(r'C:\\Varians\\Balance Sheet Quarterly.csv') as BSQ:\n",
    "                BSQ_reader = pd.read_csv(BSQ)\n",
    "\n",
    "            with open(r'C:\\Varians\\Last Price.csv') as LP:\n",
    "                LP_reader = pd.read_csv(LP)\n",
    "\n",
    "            #change date from object to datetime64\n",
    "            ISQ_reader.fiscalDateEnding=ISQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "            ISQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True) #to change string none to NaN\n",
    "            ISQ_reader.fillna(value=0,inplace=True)\n",
    "            CFQ_reader.fiscalDateEnding=CFQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "            CFQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "            CFQ_reader.fillna(value=0,inplace=True)\n",
    "            BSQ_reader.fiscalDateEnding=BSQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "            BSQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "            BSQ_reader.fillna(value=0,inplace=True)\n",
    "            BSQ_reader[\"commonStockSharesOutstanding\"] = BSQ_reader.commonStockSharesOutstanding.astype(float) #to change  data type of SO\n",
    "            LP_reader.date=LP_reader.date.astype('datetime64')\n",
    "\n",
    "            cols = BSQ_reader.columns.drop('fiscalDateEnding')\n",
    "            BSQ_reader[cols] = BSQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "            cols = ISQ_reader.columns.drop('fiscalDateEnding')\n",
    "            ISQ_reader[cols] = ISQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "            cols = CFQ_reader.columns.drop('fiscalDateEnding')\n",
    "            CFQ_reader[cols] = CFQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            #make fundamental data from quarterly to monthly and fill forward NaN data with previous quarterly data\n",
    "            #this code only apply on int or float data types\n",
    "            #resample made the date ascending, while data from time series is descending. Why not just LP became ascending? Because LP has longer date than the other data\n",
    "            ISQ_monthly=ISQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "            ISQ_monthly.fillna(method='ffill',inplace=True)\n",
    "            ISQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "            CFQ_monthly=CFQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "            CFQ_monthly.fillna(method='ffill',inplace=True)\n",
    "            CFQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "            BSQ_monthly=BSQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "            BSQ_monthly.fillna(method='ffill',inplace=True)\n",
    "            BSQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "\n",
    "            #call all data needed for calculation and clean it first and wrap it into single variable list\n",
    "            ISQ_monthly.reset_index(inplace=True)\n",
    "            SO = BSQ_monthly['commonStockSharesOutstanding']\n",
    "            netIncome = ISQ_monthly['netIncome']\n",
    "            TA = BSQ_monthly['totalAssets']\n",
    "            TL = BSQ_monthly['totalLiabilities']\n",
    "            TSE = BSQ_monthly['totalShareholderEquity']\n",
    "            cash = BSQ_monthly['cash']\n",
    "            STD = BSQ_monthly['shortTermDebt']\n",
    "            LTD = BSQ_monthly['longTermDebt']\n",
    "            EBIT = ISQ_monthly['ebit']\n",
    "            DEPR = CFQ_monthly['depreciation']\n",
    "            AMOR = BSQ_monthly['accumulatedAmortization']\n",
    "\n",
    "            dict_table=pd.DataFrame(list(zip(SO,netIncome,TA,TL,TSE,cash,STD,LTD,EBIT,DEPR,AMOR)))\n",
    "            TS_table=LP_reader.loc[0:(len(netIncome)), ['date', '4. close']]\n",
    "\n",
    "            tempaddrow=addrow(TS_table.date,ISQ_monthly.fiscalDateEnding,dict_table) #use addrow function to add row to equal TS table row with quarter table row\n",
    "            datincome=pd.DataFrame(tempaddrow[0])\n",
    "            counter=tempaddrow[1]\n",
    "            allsindex=datincome.set_axis(['SO','netIncome','TA','TL','TSE','cash','STD','LTD','EBIT','DEPR','AMOR'], axis='columns')\n",
    "            TS_table=LP_reader.loc[0:(len(netIncome)+counter), ['date', '4. close']]\n",
    "            TS_table=TS_table.rename(columns={\"4. close\": \"LastPrice\"})\n",
    "            inputmerge=TS_table.merge(allsindex, left_index=True, right_index=True)\n",
    "            #print(inputmerge)\n",
    "            #print(tempaddrow)\n",
    "\n",
    "            #calculating EPS TTM (Trailing Twelve Months) for PER input\n",
    "\n",
    "            #calculation for EPS Quarterly\n",
    "            \n",
    "            Tableeps =pd.DataFrame()\n",
    "            Tableeps ['Date'] = ISQ_reader.fiscalDateEnding\n",
    "            Tableeps ['NIQ'] = ISQ_reader.netIncome\n",
    "            Tableeps ['SOQ'] = BSQ_reader.commonStockSharesOutstanding\n",
    "            Tableeps = Tableeps.sort_index(ascending=False)\n",
    "            Tableeps = Tableeps.reset_index(drop=True)\n",
    "            EPStemps = [Tableeps.NIQ[i]/Tableeps.SOQ[i] for i in range(len(Tableeps.SOQ))]\n",
    "            NIQtemps = Tableeps.NIQ\n",
    "\n",
    "            #Make EPSTTM table from function makettm \n",
    "            EPSTTM = makettm(EPStemps,4)\n",
    "            #EPSTTM = EPSTTM.rename(columns={'EPS':'EPSTTM'})\n",
    "            Tableeps ['EPSTTM'] = pd.DataFrame(EPSTTM)\n",
    "\n",
    "            #make netIncome TTM table from function makettm\n",
    "            NITTM = makettm(NIQtemps,4)\n",
    "            Tableeps['NITTM']=pd.DataFrame(NITTM)\n",
    "\n",
    "            Tableeps=Tableeps.resample('M', on='Date').mean()\n",
    "            Tableeps.fillna(method='ffill',inplace=True)\n",
    "            Tableeps = Tableeps.sort_index(ascending=False)\n",
    "            Tableeps.reset_index(inplace=True)\n",
    "            Coldate = Tableeps.Date\n",
    "            Tableeps = Tableeps.set_index('Date')\n",
    "            temp= addrow(TS_table.date,Coldate,Tableeps)\n",
    "            TTMmonth = temp[0]\n",
    "            #print(TTMmonth)\n",
    "            #print(Tableeps)\n",
    "            #gimana ngeluarin function result ke dataframe\n",
    "\n",
    "            #calculation\n",
    "            #columns=['EPS']\n",
    "\n",
    "            Calculation = pd.DataFrame()\n",
    "\n",
    "            inputcalc = inputmerge\n",
    "            inputcalc = inputcalc.sort_index(ascending=False)\n",
    "            inputcalc = inputcalc.reset_index(drop=True)\n",
    "\n",
    "            #for i in range (len(SO)):\n",
    "            Calculation ['Date'] = inputcalc.date\n",
    "            Calculation ['LastPrice'] = inputcalc.LastPrice\n",
    "            Calculation ['ShareOut'] = inputcalc.SO\n",
    "            Calculation ['MarketCap'] = [inputcalc.LastPrice[i]*inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['EPS'] = [inputcalc.netIncome[i]/inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "\n",
    "            #Merging TTM EPS\n",
    "            temp = pd.DataFrame()\n",
    "            temp['EPSTTM'] = (TTMmonth.EPSTTM)\n",
    "            temp['NITTM'] = TTMmonth.NITTM\n",
    "            temp = temp.sort_index(ascending=False)\n",
    "            temp.reset_index(inplace=True)\n",
    "            #Calculation = Calculation.merge(EPSTTM, left_index=True, right_index=True)\n",
    "\n",
    "            Calculation ['EPSTTM'] = temp.EPSTTM\n",
    "            Calculation ['PER'] = [inputcalc.LastPrice[i]/temp.EPSTTM[i] for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['BVPS'] = [(inputcalc.TA[i]-inputcalc.TL[i])/inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['PBV'] = [Calculation.LastPrice[i]/Calculation.BVPS[i] for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['ROA%'] = [temp.NITTM[i]/inputcalc.TA[i]*100 for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['ROE%'] = [temp.NITTM[i]/inputcalc.TSE[i]*100 for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['EV'] = [Calculation.MarketCap[i]+inputcalc.cash[i]-(inputcalc.STD[i]+inputcalc.LTD[i]) for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['EBITDA'] = [inputcalc.EBIT[i]+inputcalc.DEPR[i]+inputcalc.AMOR[i] for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['EV/EBITDA'] = [Calculation.EV[i]/Calculation.EBITDA[i] for i in range(len(inputcalc.SO))]\n",
    "            Calculation ['D/E'] = [inputcalc.TL[i]/inputcalc.TSE[i] for i in range(len(inputcalc.TL))]\n",
    "            Calculation ['Debt/Totalcap'] = [(inputcalc.STD[i]+inputcalc.LTD[i])/(inputcalc.STD[i]+inputcalc.LTD[i]+inputcalc.TSE[i]) for i in range(len(inputcalc.STD))]\n",
    "            Calculation ['Debt/EBITDA'] = [(inputcalc.STD[i]+inputcalc.LTD[i])/Calculation.EBITDA[i] for i in range(len(inputcalc.STD)) ]\n",
    "\n",
    "            Calculation = Calculation.replace([np.inf, -np.inf], 0)\n",
    "            #print(Calculation.tail(30))\n",
    "            print(Calculation.dtypes)\n",
    "\n",
    "            Calculation.to_csv(r'C:\\Varians\\Calculation.csv', index=None, header=True)\n",
    "\n",
    "            #preparing pandas dataframe to list inputing to mysql\n",
    "\n",
    "            mysql_list = []\n",
    "            Unique_ID  = []\n",
    "            StockName  = [entity.upper()]*len(Calculation['Date'])  \n",
    "\n",
    "            for i in range (len(Calculation['Date'])) :\n",
    "                temp = entity + str(Calculation['Date'][i].strftime('%Y%m%d'))\n",
    "                Unique_ID.append(temp)\n",
    "                i += 1\n",
    "\n",
    "            mysql_list.append(Unique_ID)\n",
    "            mysql_list.append(StockName)\n",
    "\n",
    "            for i in list(Calculation.columns) :\n",
    "                mysql_list.append(Calculation[i])\n",
    "\n",
    "            #print(mysql_list)\n",
    "            # data table overview\n",
    "\n",
    "            df_OV = pd.Series(OV, name='Info')\n",
    "            df_OV.index.name = 'Data'\n",
    "            list_header_OV = df_OV.index.tolist()\n",
    "            #print (df_OV.head(5))\n",
    "            \n",
    "            db = connect(\"newstockmarket\")\n",
    "            cursor = db.cursor()\n",
    "\n",
    "            #--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "            ftable = \"stock_fundamental\"\n",
    "            ovtable = \"stock_overview\"\n",
    "            fintable = \"financial_report\"\n",
    "\n",
    "            create_ovtable = (\"CREATE TABLE IF NOT EXISTS {table} \"\n",
    "                              #\" ( Stock_ID int(5) NOT NULL AUTO_INCREMENT PRIMARY KEY, \"\n",
    "                              \" ( SYMBOL VARCHAR(8) NOT NULL PRIMARY KEY, ASSET_TYPE VARCHAR(30), NAME VARCHAR(20) NOT NULL, \"\n",
    "                              \" DESCRIPTION VARCHAR(255), EXCHANGE VARCHAR(10), CURRENCY VARCHAR(5), \"\n",
    "                              \" COUNTRY VARCHAR(50), SECTOR VARCHAR(50), INDUSTRY VARCHAR(50), \"\n",
    "                              \" ADDRESS VARCHAR(255), Full_Time_Employees INT(20), Fiscal_Year_End VARCHAR(15), \"\n",
    "                              \" LATEST_QUARTER DATE, DividendDate DATE, ExDividendDate DATE, \"\n",
    "                              \" LastSplitFactor DECIMAL(5,2), LastSplitDate DATE )\"\n",
    "                             )\n",
    "            create_fintable = (\"CREATE TABLE IF NOT EXISTS {table} \"\n",
    "                              \" ( NUMBER int(5) NOT NULL AUTO_INCREMENT PRIMARY KEY, \"\n",
    "                              \" SYMBOL VARCHAR(8), MARKET_CAP DECIMAL(15,2), EBITDA DECIMAL(15,2), \"\n",
    "                              \" PER DECIMAL(15,2), PEGR DECIMAL(15,2), BOOK_VALUE DECIMAL(15,2), \"\n",
    "                              \" Dividend_Per_Share DECIMAL(15,2), Dividend_Yield DECIMAL(15,2), EPS DECIMAL(15,2), \"\n",
    "                              \" Revenue_Per_Share_TTM DECIMAL(15,2), Profit_Margin DECIMAL(15,2), Operating_Margin_TTM DECIMAL(15,2), \"\n",
    "                              \" ROA_TTM DECIMAL(15,2), ROE_TTM DECIMAL(15,2), REVENUE_TTM DECIMAL(15,2), \"\n",
    "                              \" Gross_Profit_TTM DECIMAL(15,2), Diluted_EPS_TTM DECIMAL(15,2), Quarterly_Earnings_Growth_YOY DECIMAL(15,2), \"\n",
    "                              \" Quarterly_Revenue_Growth_YOY DECIMAL(15,2), Analyst_Target_Price DECIMAL(15,2), Trailing_PE DECIMAL(15,2), \"\n",
    "                              \" Forward_PE DECIMAL(15,2), Price_to_Sales_Ratio_TTM DECIMAL(15,2), PBV DECIMAL(15,2), \"\n",
    "                              \" EVtoRevenue DECIMAL(15,2), EVtoEBITDA DECIMAL(15,2), Beta DECIMAL(15,2), \"\n",
    "                              \" 52WeekHigh DECIMAL(15,2), 52WeekLow DECIMAL(15,2), 50DayMovingAverage DECIMAL(15,2), \"\n",
    "                              \" 200DayMovingAverage DECIMAL(15,2), SharesOutstanding DECIMAL(15,2), SharesFloat DECIMAL(15,2), \" \n",
    "                              \" SharesShort DECIMAL(15,2), SharesShortPriorMonth DECIMAL(15,2), ShortRatio DECIMAL(15,2), \" \n",
    "                              \" ShortPercentOutstanding DECIMAL(15,2), ShortPercentFloat DECIMAL(15,2), PercentInsiders DECIMAL(15,2), \"\n",
    "                              \" PercentInstitutions DECIMAL(15,2), ForwardAnnualDividendRate DECIMAL(15,2), ForwardAnnualDividendYield DECIMAL(15,2), \" \n",
    "                              \" PayoutRatio DECIMAL(15,2) ) \"\n",
    "                              )\n",
    "            create_ftable = (\"CREATE TABLE IF NOT EXISTS {table} \"\n",
    "                           \" ( UNIQUE_ID VARCHAR(20) NOT NULL PRIMARY KEY, SYMBOL VARCHAR(8) NOT NULL, \"\n",
    "                           \" DATE date NOT NULL, LAST_PRICE_RP decimal(8, 2) NOT NULL,\"\n",
    "                           \" SHARE_OUT decimal(15, 2) NOT NULL, MARKET_CAP_RP decimal(15, 2) NOT NULL, \"\n",
    "                           \" DEVIDEN_RP decimal(15, 2) NOT NULL,  EPSTTMM_RP decimal(15, 2) NOT NULL, \"\n",
    "                           \" PER_X decimal(15, 2) NOT NULL, BVPS_RP decimal(15, 2) NOT NULL, \"\n",
    "                           \" PBV_X decimal(15, 2) NOT NULL, ROA_PERCENT decimal(15, 2) NOT NULL, \"\n",
    "                           \" ROE_PERCENT decimal(15, 2) NOT NULL, EV decimal(15, 2) NOT NULL, \"\n",
    "                           \" EBITDA decimal(15, 2) NOT NULL, EV_EBITDA_RATIO decimal(15, 2) NOT NULL, \"\n",
    "                           \" D_E_RATIO decimal(15, 2) NOT NULL, DEBT_TOTALCAP_RATIO decimal(15, 2) NOT NULL, \"\n",
    "                           \" DEBT_EBITDA_RATIO decimal(15, 2) NOT NULL) \"\n",
    "                           )\n",
    "\n",
    "            cursor = db.cursor()\n",
    "            cursor.execute(create_ovtable.format(table=ovtable) )                    \n",
    "            cursor.execute(create_fintable.format(table=fintable, atable=fintable) )                \n",
    "            cursor.execute(create_ftable.format(table=ftable, atable=ftable) )\n",
    "\n",
    "            #------------------------------------------------------------------------------------------\n",
    "            insert_ovtable = (\"INSERT IGNORE INTO {table} \"\n",
    "                            \"( SYMBOL, ASSET_TYPE, \"\n",
    "                            \"NAME, DESCRIPTION, EXCHANGE, \"\n",
    "                            \"CURRENCY, COUNTRY, SECTOR, \"\n",
    "                            \"INDUSTRY, ADDRESS, Full_Time_Employees, \"\n",
    "                            \"Fiscal_Year_End, LATEST_QUARTER, DividendDate, \"\n",
    "                            \"ExDividendDate, LastSplitFactor, LastSplitDate ) \"\n",
    "                            \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                             )\n",
    "            temp_data = []\n",
    "            \n",
    "            for i in range(13) :\n",
    "                single_data = df_OV[list_header_OV[i]]\n",
    "                temp_data.append(single_data)\n",
    "            for i in range(55, len(list_header_OV)) :\n",
    "                single_data = df_OV[list_header_OV[i]]\n",
    "                temp_data.append(single_data)\n",
    "            cursor.execute(insert_ovtable.format(table=ovtable), temp_data)\n",
    "\n",
    "            insert_fintable = (\"INSERT IGNORE INTO {table} \"\n",
    "                                \"( SYMBOL, MARKET_CAP, EBITDA, \" \n",
    "                                \" PER, PEGR, BOOK_VALUE, \"\n",
    "                                \" Dividend_Per_Share, Dividend_Yield, EPS, \"\n",
    "                                \" Revenue_Per_Share_TTM, Profit_Margin, Operating_Margin_TTM, \"\n",
    "                                \" ROA_TTM, ROE_TTM, REVENUE_TTM, \"\n",
    "                                \" Gross_Profit_TTM, Diluted_EPS_TTM, Quarterly_Earnings_Growth_YOY, \"\n",
    "                                \" Quarterly_Revenue_Growth_YOY, Analyst_Target_Price, Trailing_PE, \"\n",
    "                                \" Forward_PE, Price_to_Sales_Ratio_TTM, PBV, \"\n",
    "                                \" EVtoRevenue, EVtoEBITDA, Beta, \"\n",
    "                                \" 52WeekHigh, 52WeekLow, 50DayMovingAverage, \"\n",
    "                                \" 200DayMovingAverage, SharesOutstanding, SharesFloat, \"\n",
    "                                \" SharesShort, SharesShortPriorMonth, ShortRatio, \"\n",
    "                                \" ShortPercentOutstanding, ShortPercentFloat, PercentInsiders, \"\n",
    "                                \" PercentInstitutions, ForwardAnnualDividendRate, ForwardAnnualDividendYield, PayoutRatio ) \"\n",
    "                                \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\n",
    "                                \" %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\n",
    "                                \" %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s )\"\n",
    "                              )\n",
    "            temp_data = []\n",
    "            temp_data.append(entity)\n",
    "            for i in range(13, 55) :\n",
    "                single_data = df_OV[list_header_OV[i]]\n",
    "                temp_data.append(single_data)\n",
    "            cursor.execute(insert_fintable.format(table=fintable), temp_data)\n",
    "\n",
    "            insert_ftable = (\"INSERT IGNORE INTO {table} \"\n",
    "                           \"(UNIQUE_ID, SYMBOL, DATE, LAST_PRICE_RP, SHARE_OUT, MARKET_CAP_RP, \"\n",
    "                           \"DEVIDEN_RP, EPSTTMM_RP, PER_X, BVPS_RP, PBV_X, ROA_PERCENT, ROE_PERCENT, \"\n",
    "                           \"EV, EBITDA, EV_EBITDA_RATIO, D_E_RATIO, DEBT_TOTALCAP_RATIO, \"\n",
    "                           \"DEBT_EBITDA_RATIO) \"\n",
    "                           \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "            j = 0\n",
    "            while j < len(mysql_list[0]) :\n",
    "                temp_data = []\n",
    "                i = 0\n",
    "                while i < len(mysql_list) :\n",
    "                    temp_data.append(str (mysql_list[i][j]))\n",
    "                    #print(project_data)\n",
    "                    i += 1\n",
    "\n",
    "                cursor.execute(insert_ftable.format(table=ftable), temp_data)\n",
    "                j += 1\n",
    "\n",
    "            db.commit()\n",
    "            db.close()\n",
    "            time.sleep(10)\n",
    "            break\n",
    "        except ValueError as e :\n",
    "            print (e)\n",
    "            if str(e) == \"Error getting data from the api, no return was given.\" :\n",
    "                print (\"Problem Ticker Name : \"+entity+\" ...Skipping\")\n",
    "                break\n",
    "                continue\n",
    "                \n",
    "            else :\n",
    "                if (step == \"step_2\") :\n",
    "                    procedure = [step_2,step_3,step_4,step_5]\n",
    "                    print (\"beginning from step 2\")\n",
    "                    randomize()\n",
    "                    time.sleep(10)  \n",
    "                elif (step == \"step_3\") :\n",
    "                    procedure = [step_3,step_4,step_5]\n",
    "                    print (\"beginning from step 3\")\n",
    "                    randomize()\n",
    "                    time.sleep(10)  \n",
    "                elif (step == \"step_4\") :\n",
    "                    procedure = [step_4,step_5]\n",
    "                    print (\"beginning from step 4\")\n",
    "                    randomize()\n",
    "                    time.sleep(10) \n",
    "                elif (step == \"step_5\") :\n",
    "                    procedure = [step_5]\n",
    "                    print (\"beginning from step 5\")\n",
    "                    randomize()\n",
    "                    time.sleep(10)  \n",
    "                else :\n",
    "                    print (\"Step 1 Problem API Limit..Try Again\")\n",
    "                    print (step)\n",
    "                    randomize()\n",
    "                    time.sleep(10)        \n",
    "#     except ValueError :\n",
    "#         time.sleep(5)\n",
    "#         continue\n",
    "        \n",
    "#######################################################################################################################################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
