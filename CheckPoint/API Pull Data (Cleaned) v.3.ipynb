{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.alphavantage import AlphaVantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpha_vantage.fundamentaldata import FundamentalData\n",
    "from alpha_vantage.timeseries import TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame as df, Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'6HZYCBP71FGOR1O5'\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "_API_KEY_TEST1 = 'G23MAAVKWB5TMPMV'\n",
    "_API_KEY_TEST2 = '6PE06AMZAM1MCGFX' #myanuarfirdaus\n",
    "_API_KEY_TEST3 = '6HZYCBP71FGOR1O5' #myanuarfirdaus23\n",
    "_API_KEY_TEST4 = 'X5LNMI2AESR1YQCU' #muh_yanuar_firdaus@yahoo.com\n",
    "_API_KEY_TEST5 = 'YBBKWRK4VSTP4GZH' #anggiengineer@yahoo.com\n",
    "\n",
    "names=[_API_KEY_TEST1,_API_KEY_TEST2,_API_KEY_TEST3,_API_KEY_TEST4,_API_KEY_TEST5]\n",
    "_API_KEY_TEST = \"\"\n",
    "def randomize () :\n",
    "    selected_names=set()\n",
    "    global _API_KEY_TEST\n",
    "    while len(selected_names)<1:\n",
    "        random.shuffle(names)\n",
    "        indx=random.randint(0,len(names)-1)\n",
    "        selected_names = names[indx]\n",
    "        _API_KEY_TEST = repr(selected_names)\n",
    "        print (_API_KEY_TEST)\n",
    "randomize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory /Varians failed\n"
     ]
    }
   ],
   "source": [
    "#creating folder on C:\n",
    "import os\n",
    "\n",
    "# define the name of the directory to be created\n",
    "path = \"/Varians\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type stock market name here : SDFBN\n"
     ]
    }
   ],
   "source": [
    "entity= input (\"Type stock market name here : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error getting data from the api, no return was given.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-dde98768cb03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Get json object with the intraday data and another with  the call's metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_income_statement_quarterly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#get income statement quarterly data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mrandomize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cash_flow_quarterly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#get cash flow quarterly data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\alpha_vantage\\alphavantage.py\u001b[0m in \u001b[0;36m_format_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_format_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             call_response, data_key, meta_data_key = func(\n\u001b[0m\u001b[0;32m    219\u001b[0m                 self, *args, **kwargs)\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'json'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'pandas'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\alpha_vantage\\alphavantage.py\u001b[0m in \u001b[0;36m_call_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m                 \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'{}{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapikey_parameter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_api_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeta_data_key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_call_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\alpha_vantage\\alphavantage.py\u001b[0m in \u001b[0;36m_handle_api_call\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[0mjson_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    357\u001b[0m                     'Error getting data from the api, no return was given.')\n\u001b[0;32m    358\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;34m\"Error Message\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error getting data from the api, no return was given."
     ]
    }
   ],
   "source": [
    "#call data API Fundamental Quarterly\n",
    "fd = FundamentalData(key=_API_KEY_TEST, output_format='pandas')\n",
    "# Get json object with the intraday data and another with  the call's metadata\n",
    "\n",
    "data1, meta_data = fd.get_income_statement_quarterly(entity)  #get income statement quarterly data\n",
    "randomize()\n",
    "data2, meta_data = fd.get_cash_flow_quarterly(entity) #get cash flow quarterly data\n",
    "randomize()\n",
    "data3, meta_data = fd.get_balance_sheet_quarterly(entity) #get balance sheet quarterly data\n",
    "\n",
    "API_URL = \"https://www.alphavantage.co/query\"\n",
    "data = {\n",
    "     \"function\": \"OVERVIEW\",\n",
    "     \"symbol\": entity,\n",
    "     \"outputsize\": \"compact\",\n",
    "     \"datatype\": \"json\",\n",
    "     \"apikey\": _API_KEY_TEST,\n",
    "     }\n",
    "response = requests.get(API_URL, data)\n",
    "Company_Overview = response.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call data timeseries last price monthly\n",
    "randomize()\n",
    "ts = TimeSeries(key=_API_KEY_TEST, output_format='pandas')\n",
    "last_price, meta_data = ts.get_monthly(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#write API to csv as buffer file\n",
    "data1.to_csv(r'C:\\Varians\\Income Statement Quarterly.csv', index=None, header=True)\n",
    "data2.to_csv(r'C:\\Varians\\Cash Flow Quarterly.csv', index=None, header=True)\n",
    "data3.to_csv(r'C:\\Varians\\Balance Sheet Quarterly.csv', index=None, header=True)\n",
    "last_price.to_csv(r'C:\\Varians\\Last Price.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OV = {}\n",
    "OV = Company_Overview\n",
    "split_OV=OV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write tuple/list overview to csv file\n",
    "with open(r'C:\\Varians\\Overview2.csv', 'w') as g:\n",
    "    writer1=csv.writer(g,lineterminator='\\n')\n",
    "    writer1.writerow(split_OV.keys())\n",
    "    writer1.writerow(split_OV.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv file to pull data for calculation variable\n",
    "import pandas as pd\n",
    "with open(r'C:\\Varians\\Income Statement Quarterly.csv') as ISQ:\n",
    "    ISQ_reader = pd.read_csv(ISQ)\n",
    "    \n",
    "with open(r'C:\\Varians\\Cash Flow Quarterly.csv') as CFQ:\n",
    "    CFQ_reader = pd.read_csv(CFQ)\n",
    "    \n",
    "with open(r'C:\\Varians\\Balance Sheet Quarterly.csv') as BSQ:\n",
    "    BSQ_reader = pd.read_csv(BSQ)\n",
    "    \n",
    "with open(r'C:\\Varians\\Last Price.csv') as LP:\n",
    "    LP_reader = pd.read_csv(LP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change date from object to datetime64\n",
    "ISQ_reader.fiscalDateEnding=ISQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "ISQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True) #to change string none to NaN\n",
    "ISQ_reader.fillna(value=0,inplace=True)\n",
    "CFQ_reader.fiscalDateEnding=CFQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "CFQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "CFQ_reader.fillna(value=0,inplace=True)\n",
    "BSQ_reader.fiscalDateEnding=BSQ_reader.fiscalDateEnding.astype('datetime64')\n",
    "BSQ_reader.replace(to_replace=['None'], value=np.nan, inplace=True)\n",
    "BSQ_reader.fillna(value=0,inplace=True)\n",
    "BSQ_reader[\"commonStockSharesOutstanding\"] = BSQ_reader.commonStockSharesOutstanding.astype(float) #to change  data type of SO\n",
    "LP_reader.date=LP_reader.date.astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = BSQ_reader.columns.drop('fiscalDateEnding')\n",
    "BSQ_reader[cols] = BSQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "cols = ISQ_reader.columns.drop('fiscalDateEnding')\n",
    "ISQ_reader[cols] = ISQ_reader[cols].apply(pd.to_numeric, errors='coerce')\n",
    "cols = CFQ_reader.columns.drop('fiscalDateEnding')\n",
    "CFQ_reader[cols] = CFQ_reader[cols].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make fundamental data from quarterly to monthly and fill forward NaN data with previous quarterly data\n",
    "#this code only apply on int or float data types\n",
    "#resample made the date ascending, while data from time series is descending. Why not just LP became ascending? Because LP has longer date than the other data\n",
    "ISQ_monthly=ISQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "ISQ_monthly.fillna(method='ffill',inplace=True)\n",
    "ISQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "CFQ_monthly=CFQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "CFQ_monthly.fillna(method='ffill',inplace=True)\n",
    "CFQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)\n",
    "BSQ_monthly=BSQ_reader.resample('M', on='fiscalDateEnding').mean()\n",
    "BSQ_monthly.fillna(method='ffill',inplace=True)\n",
    "BSQ_monthly.sort_values(by=['fiscalDateEnding'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for add rows to fundamental rows to be equal with timeseries rows and fill nan\n",
    "def addrow(source,target,ori_table):\n",
    "    data=[]\n",
    "    #y=pd.DataFrame()\n",
    "    counter=0\n",
    "    for i in range(0,10):\n",
    "        if source[i]==target[0]:\n",
    "            break\n",
    "        counter+=1\n",
    "    for j in range(0,counter):\n",
    "        data.insert(j, {np.NaN,np.NaN,np.NaN})\n",
    "    y=pd.concat([pd.DataFrame(data), ori_table], ignore_index=True) #repeat for all variable\n",
    "    y.fillna(method='bfill',inplace=True)\n",
    "    return [y,counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call all data needed for calculation and clean it first and wrap it into single variable list\n",
    "ISQ_monthly.reset_index(inplace=True)\n",
    "SO = BSQ_monthly['commonStockSharesOutstanding']\n",
    "netIncome = ISQ_monthly['netIncome']\n",
    "TA = BSQ_monthly['totalAssets']\n",
    "TL = BSQ_monthly['totalLiabilities']\n",
    "TSE = BSQ_monthly['totalShareholderEquity']\n",
    "cash = BSQ_monthly['cash']\n",
    "STD = BSQ_monthly['shortTermDebt']\n",
    "LTD = BSQ_monthly['longTermDebt']\n",
    "EBIT = ISQ_monthly['ebit']\n",
    "DEPR = CFQ_monthly['depreciation']\n",
    "AMOR = BSQ_monthly['accumulatedAmortization']\n",
    "\n",
    "dict_table=pd.DataFrame(list(zip(SO,netIncome,TA,TL,TSE,cash,STD,LTD,EBIT,DEPR,AMOR)))\n",
    "TS_table=LP_reader.loc[0:(len(netIncome)), ['date', '4. close']]\n",
    "\n",
    "tempaddrow=addrow(TS_table.date,ISQ_monthly.fiscalDateEnding,dict_table) #use addrow function to add row to equal TS table row with quarter table row\n",
    "datincome=pd.DataFrame(tempaddrow[0])\n",
    "counter=tempaddrow[1]\n",
    "allsindex=datincome.set_axis(['SO','netIncome','TA','TL','TSE','cash','STD','LTD','EBIT','DEPR','AMOR'], axis='columns')\n",
    "TS_table=LP_reader.loc[0:(len(netIncome)+counter), ['date', '4. close']]\n",
    "TS_table=TS_table.rename(columns={\"4. close\": \"LastPrice\"})\n",
    "inputmerge=TS_table.merge(allsindex, left_index=True, right_index=True)\n",
    "print(inputmerge)\n",
    "#print(tempaddrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for making TTM data\n",
    "def makettm(tabtemp,x):\n",
    "    tabtemp = DataFrame(tabtemp)\n",
    "    width = x\n",
    "    shifted = tabtemp.shift(0)\n",
    "    window = shifted.rolling(window=width)\n",
    "    test = window.sum()\n",
    "    complete = test.fillna(value=0)\n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculating EPS TTM (Trailing Twelve Months) for PER input\n",
    "\n",
    "#calculation for EPS Quarterly\n",
    "from pandas import DataFrame\n",
    "Tableeps =pd.DataFrame()\n",
    "Tableeps ['Date'] = ISQ_reader.fiscalDateEnding\n",
    "Tableeps ['NIQ'] = ISQ_reader.netIncome\n",
    "Tableeps ['SOQ'] = BSQ_reader.commonStockSharesOutstanding\n",
    "Tableeps = Tableeps.sort_index(ascending=False)\n",
    "Tableeps = Tableeps.reset_index(drop=True)\n",
    "EPStemps = [Tableeps.NIQ[i]/Tableeps.SOQ[i] for i in range(len(Tableeps.SOQ))]\n",
    "NIQtemps = Tableeps.NIQ\n",
    "\n",
    "#Make EPSTTM table from function makettm \n",
    "EPSTTM = makettm(EPStemps,4)\n",
    "#EPSTTM = EPSTTM.rename(columns={'EPS':'EPSTTM'})\n",
    "Tableeps ['EPSTTM'] = pd.DataFrame(EPSTTM)\n",
    "\n",
    "#make netIncome TTM table from function makettm\n",
    "NITTM = makettm(NIQtemps,4)\n",
    "Tableeps['NITTM']=pd.DataFrame(NITTM)\n",
    "\n",
    "Tableeps=Tableeps.resample('M', on='Date').mean()\n",
    "Tableeps.fillna(method='ffill',inplace=True)\n",
    "Tableeps = Tableeps.sort_index(ascending=False)\n",
    "Tableeps.reset_index(inplace=True)\n",
    "Coldate = Tableeps.Date\n",
    "Tableeps = Tableeps.set_index('Date')\n",
    "temp= addrow(TS_table.date,Coldate,Tableeps)\n",
    "TTMmonth = temp[0]\n",
    "print(TTMmonth)\n",
    "print(Tableeps)\n",
    "#gimana ngeluarin function result ke dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#calculation\n",
    "#columns=['EPS']\n",
    "from pandas import DataFrame\n",
    "Calculation = pd.DataFrame()\n",
    "\n",
    "inputcalc = inputmerge\n",
    "inputcalc = inputcalc.sort_index(ascending=False)\n",
    "inputcalc = inputcalc.reset_index(drop=True)\n",
    "\n",
    "#for i in range (len(SO)):\n",
    "Calculation ['Date'] = inputcalc.date\n",
    "Calculation ['LastPrice'] = inputcalc.LastPrice\n",
    "Calculation ['ShareOut'] = inputcalc.SO\n",
    "Calculation ['MarketCap'] = [inputcalc.LastPrice[i]*inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EPS'] = [inputcalc.netIncome[i]/inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "\n",
    "#Merging TTM EPS\n",
    "temp = pd.DataFrame()\n",
    "temp['EPSTTM'] = (TTMmonth.EPSTTM)\n",
    "temp['NITTM'] = TTMmonth.NITTM\n",
    "temp = temp.sort_index(ascending=False)\n",
    "temp.reset_index(inplace=True)\n",
    "#Calculation = Calculation.merge(EPSTTM, left_index=True, right_index=True)\n",
    "\n",
    "Calculation ['EPSTTM'] = temp.EPSTTM\n",
    "Calculation ['PER'] = [inputcalc.LastPrice[i]/temp.EPSTTM[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['BVPS'] = [(inputcalc.TA[i]-inputcalc.TL[i])/inputcalc.SO[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['PBV'] = [Calculation.LastPrice[i]/Calculation.BVPS[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['ROA%'] = [temp.NITTM[i]/inputcalc.TA[i]*100 for i in range(len(inputcalc.SO))]\n",
    "Calculation ['ROE%'] = [temp.NITTM[i]/inputcalc.TSE[i]*100 for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EV'] = [Calculation.MarketCap[i]+inputcalc.cash[i]-(inputcalc.STD[i]+inputcalc.LTD[i]) for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EBITDA'] = [inputcalc.EBIT[i]+inputcalc.DEPR[i]+inputcalc.AMOR[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['EV/EBITDA'] = [Calculation.EV[i]/Calculation.EBITDA[i] for i in range(len(inputcalc.SO))]\n",
    "Calculation ['D/E'] = [inputcalc.TL[i]/inputcalc.TSE[i] for i in range(len(inputcalc.TL))]\n",
    "Calculation ['Debt/Totalcap'] = [(inputcalc.STD[i]+inputcalc.LTD[i])/(inputcalc.STD[i]+inputcalc.LTD[i]+inputcalc.TSE[i]) for i in range(len(inputcalc.STD))]\n",
    "Calculation ['Debt/EBITDA'] = [(inputcalc.STD[i]+inputcalc.LTD[i])/Calculation.EBITDA[i] for i in range(len(inputcalc.STD)) ]\n",
    "\n",
    "Calculation = Calculation.replace([np.inf, -np.inf], 0)\n",
    "print(Calculation.tail(30))\n",
    "print(Calculation.dtypes)\n",
    "\n",
    "Calculation.to_csv(r'C:\\Varians\\Calculation.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing pandas dataframe to list inputing to mysql\n",
    "\n",
    "import time\n",
    "mysql_list = []\n",
    "Unique_ID  = []\n",
    "StockName  = [entity.upper()]*len(Calculation['Date'])  \n",
    "\n",
    "for i in range (len(Calculation['Date'])) :\n",
    "    temp = entity + str(Calculation['Date'][i].strftime('%Y%m%d'))\n",
    "    Unique_ID.append(temp)\n",
    "    i += 1\n",
    "\n",
    "mysql_list.append(Unique_ID)\n",
    "mysql_list.append(StockName)\n",
    "\n",
    "for i in list(Calculation.columns) :\n",
    "    mysql_list.append(Calculation[i])\n",
    "    \n",
    "#print(mysql_list)\n",
    "# data table overview\n",
    "\n",
    "df_OV = pd.Series(OV, name='Info')\n",
    "df_OV.index.name = 'Data'\n",
    "list_header_OV = df_OV.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import module for mysql \n",
    "import mplfinance as mpf\n",
    "from os import path\n",
    "import mysql.connector as mysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(db_name):\n",
    "    try:\n",
    "        return mysql.connect(\n",
    "            host='localhost',\n",
    "            user='root',\n",
    "            password='minyak23',\n",
    "            database=db_name)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = connect(\"newstockmarket\")\n",
    "    cursor = db.cursor()\n",
    "    \n",
    "    #--------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "    ftable = \"stock_fundamental\"\n",
    "    ovtable = \"stock_overview\"\n",
    "    fintable = \"financial_report\"\n",
    "      \n",
    "    create_ovtable = (\"CREATE TABLE IF NOT EXISTS {table} \"\n",
    "                      #\" ( Stock_ID int(5) NOT NULL AUTO_INCREMENT PRIMARY KEY, \"\n",
    "                      \" ( SYMBOL VARCHAR(8) NOT NULL PRIMARY KEY, ASSET_TYPE VARCHAR(30), NAME VARCHAR(20) NOT NULL, \"\n",
    "                      \" DESCRIPTION VARCHAR(255), EXCHANGE VARCHAR(10), CURRENCY VARCHAR(5), \"\n",
    "                      \" COUNTRY VARCHAR(50), SECTOR VARCHAR(50), INDUSTRY VARCHAR(50), \"\n",
    "                      \" ADDRESS VARCHAR(255), Full_Time_Employees INT(20), Fiscal_Year_End VARCHAR(15), \"\n",
    "                      \" LATEST_QUARTER DATE, DividendDate DATE, ExDividendDate DATE, \"\n",
    "                      \" LastSplitFactor DECIMAL(5,2), LastSplitDate DATE )\"\n",
    "                     )\n",
    "    create_fintable = (\"CREATE TABLE IF NOT EXISTS {table} \"\n",
    "                      \" ( NUMBER int(5) NOT NULL AUTO_INCREMENT PRIMARY KEY, \"\n",
    "                      \" SYMBOL VARCHAR(8), MARKET_CAP DECIMAL(15,2), EBITDA DECIMAL(15,2), \"\n",
    "                      \" PER DECIMAL(15,2), PEGR DECIMAL(15,2), BOOK_VALUE DECIMAL(15,2), \"\n",
    "                      \" Dividend_Per_Share DECIMAL(15,2), Dividend_Yield DECIMAL(15,2), EPS DECIMAL(15,2), \"\n",
    "                      \" Revenue_Per_Share_TTM DECIMAL(15,2), Profit_Margin DECIMAL(15,2), Operating_Margin_TTM DECIMAL(15,2), \"\n",
    "                      \" ROA_TTM DECIMAL(15,2), ROE_TTM DECIMAL(15,2), REVENUE_TTM DECIMAL(15,2), \"\n",
    "                      \" Gross_Profit_TTM DECIMAL(15,2), Diluted_EPS_TTM DECIMAL(15,2), Quarterly_Earnings_Growth_YOY DECIMAL(15,2), \"\n",
    "                      \" Quarterly_Revenue_Growth_YOY DECIMAL(15,2), Analyst_Target_Price DECIMAL(15,2), Trailing_PE DECIMAL(15,2), \"\n",
    "                      \" Forward_PE DECIMAL(15,2), Price_to_Sales_Ratio_TTM DECIMAL(15,2), PBV DECIMAL(15,2), \"\n",
    "                      \" EVtoRevenue DECIMAL(15,2), EVtoEBITDA DECIMAL(15,2), Beta DECIMAL(15,2), \"\n",
    "                      \" 52WeekHigh DECIMAL(15,2), 52WeekLow DECIMAL(15,2), 50DayMovingAverage DECIMAL(15,2), \"\n",
    "                      \" 200DayMovingAverage DECIMAL(15,2), SharesOutstanding DECIMAL(15,2), SharesFloat DECIMAL(15,2), \" \n",
    "                      \" SharesShort DECIMAL(15,2), SharesShortPriorMonth DECIMAL(15,2), ShortRatio DECIMAL(15,2), \" \n",
    "                      \" ShortPercentOutstanding DECIMAL(15,2), ShortPercentFloat DECIMAL(15,2), PercentInsiders DECIMAL(15,2), \"\n",
    "                      \" PercentInstitutions DECIMAL(15,2), ForwardAnnualDividendRate DECIMAL(15,2), ForwardAnnualDividendYield DECIMAL(15,2), \" \n",
    "                      \" PayoutRatio DECIMAL(15,2) ) \"\n",
    "                      )\n",
    "    create_ftable = (\"CREATE TABLE IF NOT EXISTS {table} \"\n",
    "                   \" ( UNIQUE_ID VARCHAR(20) NOT NULL PRIMARY KEY, SYMBOL VARCHAR(8) NOT NULL, \"\n",
    "                   \" DATE date NOT NULL, LAST_PRICE_RP decimal(8, 2) NOT NULL,\"\n",
    "                   \" SHARE_OUT decimal(15, 2) NOT NULL, MARKET_CAP_RP decimal(15, 2) NOT NULL, \"\n",
    "                   \" DEVIDEN_RP decimal(15, 2) NOT NULL,  EPSTTMM_RP decimal(15, 2) NOT NULL, \"\n",
    "                   \" PER_X decimal(15, 2) NOT NULL, BVPS_RP decimal(15, 2) NOT NULL, \"\n",
    "                   \" PBV_X decimal(15, 2) NOT NULL, ROA_PERCENT decimal(15, 2) NOT NULL, \"\n",
    "                   \" ROE_PERCENT decimal(15, 2) NOT NULL, EV decimal(15, 2) NOT NULL, \"\n",
    "                   \" EBITDA decimal(15, 2) NOT NULL, EV_EBITDA_RATIO decimal(15, 2) NOT NULL, \"\n",
    "                   \" D_E_RATIO decimal(15, 2) NOT NULL, DEBT_TOTALCAP_RATIO decimal(15, 2) NOT NULL, \"\n",
    "                   \" DEBT_EBITDA_RATIO decimal(15, 2) NOT NULL) \"\n",
    "                   )\n",
    "\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(create_ovtable.format(table=ovtable) )                    \n",
    "    cursor.execute(create_fintable.format(table=fintable, atable=fintable) )                \n",
    "    cursor.execute(create_ftable.format(table=ftable, atable=ftable) )\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "    insert_ovtable = (\"INSERT IGNORE INTO {table} \"\n",
    "                    \"( SYMBOL, ASSET_TYPE, \"\n",
    "                    \"NAME, DESCRIPTION, EXCHANGE, \"\n",
    "                    \"CURRENCY, COUNTRY, SECTOR, \"\n",
    "                    \"INDUSTRY, ADDRESS, Full_Time_Employees, \"\n",
    "                    \"Fiscal_Year_End, LATEST_QUARTER, DividendDate, \"\n",
    "                    \"ExDividendDate, LastSplitFactor, LastSplitDate ) \"\n",
    "                    \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "                     )\n",
    "    temp_data = []\n",
    "    for i in range(13) :\n",
    "        single_data = df_OV[list_header_OV[i]]\n",
    "        temp_data.append(single_data)\n",
    "    for i in range(55, len(list_header_OV)) :\n",
    "        single_data = df_OV[list_header_OV[i]]\n",
    "        temp_data.append(single_data)\n",
    "    cursor.execute(insert_ovtable.format(table=ovtable), temp_data)\n",
    "    \n",
    "    insert_fintable = (\"INSERT IGNORE INTO {table} \"\n",
    "                        \"( SYMBOL, MARKET_CAP, EBITDA, \" \n",
    "                        \" PER, PEGR, BOOK_VALUE, \"\n",
    "                        \" Dividend_Per_Share, Dividend_Yield, EPS, \"\n",
    "                        \" Revenue_Per_Share_TTM, Profit_Margin, Operating_Margin_TTM, \"\n",
    "                        \" ROA_TTM, ROE_TTM, REVENUE_TTM, \"\n",
    "                        \" Gross_Profit_TTM, Diluted_EPS_TTM, Quarterly_Earnings_Growth_YOY, \"\n",
    "                        \" Quarterly_Revenue_Growth_YOY, Analyst_Target_Price, Trailing_PE, \"\n",
    "                        \" Forward_PE, Price_to_Sales_Ratio_TTM, PBV, \"\n",
    "                        \" EVtoRevenue, EVtoEBITDA, Beta, \"\n",
    "                        \" 52WeekHigh, 52WeekLow, 50DayMovingAverage, \"\n",
    "                        \" 200DayMovingAverage, SharesOutstanding, SharesFloat, \"\n",
    "                        \" SharesShort, SharesShortPriorMonth, ShortRatio, \"\n",
    "                        \" ShortPercentOutstanding, ShortPercentFloat, PercentInsiders, \"\n",
    "                        \" PercentInstitutions, ForwardAnnualDividendRate, ForwardAnnualDividendYield, PayoutRatio ) \"\n",
    "                        \" VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\n",
    "                        \" %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, \"\n",
    "                        \" %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s )\"\n",
    "                      )\n",
    "    temp_data = []\n",
    "    temp_data.append(entity)\n",
    "    for i in range(13, 55) :\n",
    "        single_data = df_OV[list_header_OV[i]]\n",
    "        temp_data.append(single_data)\n",
    "    cursor.execute(insert_fintable.format(table=fintable), temp_data)\n",
    "\n",
    "    insert_ftable = (\"INSERT IGNORE INTO {table} \"\n",
    "                   \"(UNIQUE_ID, SYMBOL, DATE, LAST_PRICE_RP, SHARE_OUT, MARKET_CAP_RP, \"\n",
    "                   \"DEVIDEN_RP, EPSTTMM_RP, PER_X, BVPS_RP, PBV_X, ROA_PERCENT, ROE_PERCENT, \"\n",
    "                   \"EV, EBITDA, EV_EBITDA_RATIO, D_E_RATIO, DEBT_TOTALCAP_RATIO, \"\n",
    "                   \"DEBT_EBITDA_RATIO) \"\n",
    "                   \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "    j = 0\n",
    "    while j < len(mysql_list[0]) :\n",
    "        temp_data = []\n",
    "        i = 0\n",
    "        while i < len(mysql_list) :\n",
    "            temp_data.append(str (mysql_list[i][j]))\n",
    "            #print(project_data)\n",
    "            i += 1\n",
    "        \n",
    "        cursor.execute(insert_ftable.format(table=ftable), temp_data)\n",
    "        j += 1\n",
    "        \n",
    "    db.commit()\n",
    "\n",
    "    #select_table = (\"SELECT * FROM {table} \")\n",
    "    #cursor.execute(select_table.format(table=ftable))\n",
    "    #project_records = cursor.fetchall()\n",
    "    \n",
    "    #print(project_records)\n",
    "\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
